from services.search.azure_search import AzureSearchService
from api.services.azure_openai_service import AzureOpenAIService 
class EnhancedRAGService:
    def __init__(self):
        self.search_service = AzureSearchService()
        self.openai_service = AzureOpenAIService()  #  Utiliser le service

    def analyze_with_context(self, user_query):
        """Analyse RAG avec prompt optimis√© pour une meilleure int√©gration du contexte"""
        
        try:
            # 1. Recherche contextuelle dans Azure AI Search
            search_results = self.search_service.search_analyses(user_query, top=5)
            
            # 2. V√©rifier si on a du contexte pertinent
            if not search_results:
                fallback_prompt = f"""
Tu es FactGuard, un expert en v√©rification d'informations.

INFORMATION √Ä ANALYSER :
{user_query}

INSTRUCTION :
Effectue une analyse de fact-checking standard car aucune analyse similaire n'a √©t√© trouv√©e dans l'historique.

Fournis ton analyse sous ce format :
- **√âvaluation** : [Vraie/Fausse/Partiellement vraie/Impossible √† v√©rifier]
- **Explication** : [Explication d√©taill√©e]
- **Score de confiance** : [0-100]%
- **Sources recommand√©es** : [Types de sources √† consulter]
- **Note** : Analyse effectu√©e sans contexte historique
                """
                
                
                result = self.openai_service.analyze_information(fallback_prompt)
                
                return {
                    'analysis_result': result,
                    'context_used': "Aucun contexte historique trouv√© - Analyse standard effectu√©e",
                    'sources_count': 0,
                    'search_query': user_query,
                    'mode': 'standard'
                }
            
            # 3. Construire un contexte riche et structur√©
            context_sections = []
            for i, result in enumerate(search_results, 1):
                context_section = f"""
ANALYSE #{i} (Score: {result.get('confidence_score', 'N/A')}) :
‚Ä¢ Contenu analys√© : {result['content'][:400]}
‚Ä¢ Verdict pr√©c√©dent : {result['analysis_result'][:300]}
‚Ä¢ Analys√© par : {result.get('username', 'Utilisateur')}
‚Ä¢ Date : {result.get('created_at', 'Date inconnue')}
---"""
                context_sections.append(context_section)
            
            rich_context = "\n".join(context_sections)
            
            # 4. Prompt optimis√© avec instructions sp√©cifiques
            enhanced_prompt = f"""
Tu es FactGuard Pro, syst√®me expert de fact-checking avec acc√®s √† une base d'analyses historiques.

=== CONTEXTE HISTORIQUE PERTINENT ===
{rich_context}

=== NOUVELLE INFORMATION √Ä ANALYSER ===
{user_query}

=== INSTRUCTIONS SP√âCIFIQUES ===
1. COMPARE cette nouvelle information avec les analyses historiques ci-dessus
2. IDENTIFIE les similitudes, contradictions ou patterns r√©currents
3. UTILISE l'expertise accumul√©e pour enrichir ton √©valuation
4. CITE les analyses pr√©c√©dentes pertinentes (ex: "Comme observ√© dans l'Analyse #2...")
5. JUSTIFIE ton verdict en t'appuyant sur le contexte historique

=== FORMAT DE R√âPONSE OBLIGATOIRE ===
**üîç ANALYSE COMPARATIVE :**
[Comparaison avec les analyses historiques similaires]

**üìä VERDICT ENRICHI :**
[√âvaluation bas√©e sur l'expertise accumul√©e]

**üéØ SCORE DE CONFIANCE :**
[0-100]% (justifi√© par l'historique)

**üìö SOURCES CONTEXTUELLES :**
[R√©f√©rences aux analyses pr√©c√©dentes utilis√©es]

**üí° INSIGHTS SUPPL√âMENTAIRES :**
[Patterns d√©tect√©s ou recommandations bas√©es sur l'historique]

IMPORTANT : Tu DOIS utiliser et citer le contexte historique dans ta r√©ponse.
            """
            
            # 5. Appel GPT-4o avec le prompt optimis√©
            result = self.openai_service.analyze_information(enhanced_prompt)
            
            return {
                'analysis_result': result,
                'context_used': rich_context,
                'sources_count': len(search_results),
                'search_query': user_query,
                'enhanced_prompt': enhanced_prompt,
                'mode': 'rag_enhanced'
            }
            
        except Exception as e:
            # Fallback en cas d'erreur
            return {
                'analysis_result': f"Erreur lors de l'analyse RAG. Analyse standard pour: {user_query}",
                'context_used': f"Erreur: {str(e)}",
                'sources_count': 0,
                'error': str(e),
                'mode': 'error_fallback'
            }

       # ‚úÖ AJOUT : M√©thode manquante pour respecter le protocole
    def get_similar_analyses(self, query: str, limit: int = 5) -> List[Dict]:
        """Recherche d'analyses similaires dans l'historique"""
        try:
            # Utiliser Azure AI Search pour trouver des analyses similaires
            similar_sources = self._search_relevant_sources(query, top_k=limit)
            
            # Formatter les r√©sultats pour correspondre au protocole
            similar_analyses = []
            for source in similar_sources:
                similar_analyses.append({
                    'content': source.get('content', ''),
                    'confidence_score': source.get('reliability_score', 0),
                    'title': source.get('title', ''),
                    'url': source.get('url', ''),
                    'relevance_score': source.get('@search.score', 0)
                })
            
            return similar_analyses
            
        except Exception as e:
            logger.error(f"‚ùå Erreur recherche analyses similaires: {e}")
            return []

# Alias pour compatibilit√© (si utilis√©)
RAGService = EnhancedRAGService